â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        YOU (CEO / User)      â”‚
â”‚  (Streamlit Chat UI - app.py)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚  User Question
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        agent.py (BRAIN)      â”‚
â”‚  - System Prompt (AI COS)   â”‚
â”‚  - Chat History / Memory   â”‚
â”‚  - Tool Selection Logic    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚  1ï¸âƒ£ First LLM Call
                â”‚  â†’ "Which tool(s) do I need?"
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        OPENAI LLM            â”‚
â”‚  - Reads System Prompt      â”‚
â”‚  - Reads Your Question      â”‚
â”‚  - Sees Available Tools     â”‚
â”‚  - Decides Tool Calls       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚  Tool Call(s)
                â”‚  e.g.:
                â”‚  â†’ tool_roas_by_channel
                â”‚  â†’ tool_churn_rate
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     execute_tool() (agent.py)â”‚
â”‚  - Dispatches tool name     â”‚
â”‚  - Calls tools.py function â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        tools.py (ADAPTER)   â”‚
â”‚  - Calls analytics.py      â”‚
â”‚  - Converts DF â†’ JSON      â”‚
â”‚  - Returns dict / list     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     analytics.py (BI CORE)  â”‚
â”‚  - Opens CSV with Pandas   â”‚
â”‚  - Computes real metrics  â”‚
â”‚  - Returns DataFrames     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        data/*.csv           â”‚
â”‚  - sales.csv                â”‚
â”‚  - customers.csv           â”‚
â”‚  - marketing.csv           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ” FULL RUNTIME FLOW (STEP-BY-STEP)
âœ… STEP 1 â€” You Type a Question (UI Layer)

From Streamlit (app.py):

response = run_ceo_agent(st.session_state.messages)


Example question:

"Where am I losing money?"

This becomes:

conversation = [
  {"role": "user", "content": "Where am I losing money?"}
]

âœ… STEP 2 â€” agent.py Adds the CEO Identity (Brain Setup)
messages = [
  {"role": "system", "content": SYSTEM_PROMPT},
  {"role": "user", "content": "Where am I losing money?"}
]


This tells the LLM:

You are the AI Chief of Staff

You must use real tools

You must not hallucinate

You must give strategic advice

âœ… STEP 3 â€” FIRST LLM CALL: â€œWhich tools should I use?â€
response = client.chat.completions.create(
    model=MODEL,
    messages=messages,
    tools=OPENAI_TOOLS,
    tool_choice="auto",
)


The LLM now mentally does:

â€œTo find money leaks, I need:

Churn rate

ROAS by channelâ€

So it returns:

tool_calls = [
  { name: "tool_churn_rate", arguments: "{}" },
  { name: "tool_roas_by_channel", arguments: "{}" }
]

âœ… STEP 4 â€” Python Executes Each Tool

Inside this block:

result = execute_tool(func, args)


This calls:

agent.py â†’ tools.py â†’ analytics.py â†’ CSV file


Example:

tool_roas_by_channel
â†’ roas_by_channel(_marketing_df)
â†’ computes ROAS
â†’ returns DataFrame
â†’ converted to JSON

âœ… STEP 5 â€” Tool Results Are Injected Back into Chat

This is what the LLM now sees:

{
  "role": "tool",
  "name": "tool_roas_by_channel",
  "content": [
    {"channel": "Instagram", "ROAS": 0.94},
    {"channel": "Google", "ROAS": 0.56},
    {"channel": "Influencers", "ROAS": 0.43}
  ]
}


and

{
  "role": "tool",
  "name": "tool_churn_rate",
  "content": {"churn_rate": 0.246}
}

âœ… STEP 6 â€” SECOND LLM CALL: â€œInterpret the Numbersâ€

Now the LLM sees:

Original question

Its own tool calls

REAL computed data

Then it reasons:

Churn is high â†’ customer loss

Google + Influencers ROAS < 1 â†’ losing money

And replies:

â€œYou are losing money due to high churn and inefficient Google & Influencer adsâ€¦â€

âœ… This is pure CEO reasoning on real data.

âœ… STEP 7 â€” Final Answer Goes Back to UI

Streamlit displays the final response in chat bubbles.

ğŸ§© WHO DOES WHAT (CLEAR SEPARATION OF RESPONSIBILITY)
File	Role
data/*.csv	Raw business truth
analytics.py	Math & business KPIs
tools.py	Converts KPIs â†’ JSON
agent.py	Decides what to compute & explains it
app.py	Chat interface
OpenAI LLM	Strategic reasoning & communication

